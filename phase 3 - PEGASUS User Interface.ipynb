{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2973e800",
   "metadata": {},
   "source": [
    "<font size=\"5\">Article Summarizer Application using PEGASUS model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6a343c",
   "metadata": {},
   "source": [
    "<font color=blue><font size=\"3\">in this pipeline, i've created a simple application for summarization that you can use without any previous experience in Natural Language Processing, HuggingFace Transformers, Pre-Trained Models, Tokenization or Encoding & Decoding Architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076f4c40",
   "metadata": {},
   "source": [
    "<font color=blue><font size=\"3\">I use the \"Newspaper3k\" library to extract the text from any article links and \"Gradio\" library to create a friendly UI and then summarize them with \"PEGASUS\" model for abstractive summarization using \"PEGASUS-XSUM\" pre-trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e144bab",
   "metadata": {},
   "source": [
    "<font color=blue><font size=\"3\">run the whole code once to launch the UI interface in a new tab on the default browser, and then copy and paste the link of the article that needed to be summarized inside the URL box, click submit and wait for the summary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed40171",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\user\\miniconda3\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#install newspaper3k : for extracting & curating articles\n",
    "\n",
    "!pip install newspaper3k transformers gradio --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da056210",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Loading some dependencies\n",
    "\n",
    "#nlkt : provides newspaper3k with tokenizing functionalities\n",
    "#transformers :  provides general-purpose architectures (PEGASUS) for Natural Language Understanding (NLU)\n",
    "#Gradio : provides you with A friendly customizable graphical web interface so that anyone can use it\n",
    "\n",
    "from newspaper import Article\n",
    "from newspaper import Config\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "from transformers import pipeline\n",
    "import gradio as gr\n",
    "from gradio.mix import Parallel, Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aff37b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instead of making the users copy the text from any website and paste it in a summary code, this simple method \n",
    "#is for them to paste the link and then create a summary for the users without any programing.\n",
    "#this function will extract the article text using the newspaper3k library\n",
    "\n",
    "#USER_AGENT : allow us to extract information from some websites without getting \"http\" errors.\n",
    "\n",
    "def auto_link(url):\n",
    "  USER_AGENT = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:78.0) Gecko/20100101 Firefox/78.0'\n",
    "  configuration = Config()\n",
    "  configuration.browser_user_agent = USER_AGENT\n",
    "  configuration.request_timeout = 10\n",
    "  abstract = Article(url, config =configuration)\n",
    "  abstract.download()\n",
    "  abstract.parse()\n",
    "  text = abstract.text\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "380af160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching model from: https://huggingface.co/google/pegasus-xsum\n",
      "Running on local URL:  http://127.0.0.1:7861/\n",
      "Running on public URL: https://43499.gradio.app\n",
      "\n",
      "This share link will expire in 72 hours. To get longer links, send an email to: support@gradio.app\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"500\"\n",
       "            src=\"https://43499.gradio.app\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x289d5699e20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<Flask 'gradio.networking'>,\n",
       " 'http://127.0.0.1:7861/',\n",
       " 'https://43499.gradio.app')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Gradio will help us to create a friendly User Interface.\n",
    "\n",
    "#example_urls: provide the users with some examples, includes links with random articles from websites like wikipedia and CNN\n",
    "\n",
    "#google/pegasus-xsum : i used this pre-trained model because after many trials, its output was the most precise summary\n",
    "\n",
    "\n",
    "extract = gr.Interface(auto_link, 'text', 'text')\n",
    "abstractive_summarization = gr.Interface.load(\"huggingface/google/pegasus-xsum\")\n",
    "\n",
    "example_urls = [['https://www.ibm.com/cloud/learn/machine-learning/'],\n",
    "                ['https://www.cnn.com/2021/11/24/us/arctic-ocean-early-warming-climate/index.html/'],\n",
    "                ['https://www.britannica.com/topic/Pyramids-of-Giza']]\n",
    "\n",
    "title =  '''\n",
    "        Life is Short, Copy $ Paste your Link below and let PEGASUS summarize your article.\n",
    "        (you could use one of these links below to see how it works)\n",
    "        \n",
    "        '''\n",
    "\n",
    "UI_summarizer = Series(extract, abstractive_summarization, inputs = gr.inputs.Textbox (lines = 2, label = 'URL'),\n",
    "               outputs = 'text', title = 'Abstractive Summarization App', theme = 'huggingface', description = title, \n",
    "               examples= example_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f96288",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(share=True): allows to share and run this task on other devices without this jupyter notebook for 72 hours only (public URL)\n",
    "#(inbrowser=True): allows to launch the interface in a new tab on the default browser\n",
    "\n",
    "UI_summarizer.launch(share = True, inbrowser = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
